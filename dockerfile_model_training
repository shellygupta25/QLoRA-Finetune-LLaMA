# CUDA runtime with Python support
FROM nvidia/cuda:12.6.2-runtime-ubuntu22.04

# Install Python
RUN apt-get update && \
    apt-get install -y python3 python3-pip && \
    ln -s /usr/bin/python3 /usr/bin/python && \
    pip install --upgrade pip

WORKDIR /app


# Copy requirements
COPY requirements.txt .

# Install PyTorch with CUDA 12.6 FIRST (not in requirements.txt)
RUN pip install torch==2.9.1 --index-url https://download.pytorch.org/whl/cu126
RUN pip install --no-cache-dir "transformers[torch]==4.57.3"

# Install rest of dependencies (without torch and transformer)
RUN pip install --no-cache-dir -r requirements.txt

# Copy code
COPY . /app/

# Run script
CMD ["python", "finetune_LLaMA.py"]


